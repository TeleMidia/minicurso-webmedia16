\documentclass{SBCbookchapter}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage[utf8]{inputenc}
\usepackage[english,brazilian]{babel}
\usepackage[protrusion=true,expansion]{microtype}
\usepackage{hyperref}
\hypersetup{colorlinks=true,allcolors=black}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{float}
\usepackage{natbib}
\setlength{\bibsep}{0.0pt}
%%
\usepackage{tikz}
\usetikzlibrary{arrows,calc,positioning}
\newdimen\hdim                  % element height
\newdimen\wdim                  % element width
\newdimen\odim                  % offset distance
\hdim=2.25em
\wdim=2.36\hdim
\odim=\hdim
\tikzstyle{element}=[
    draw=black!60,
  font={\scriptsize\sffamily},
  inner sep=0pt,
  minimum height=\hdim,
  minimum width=\wdim,
  outer sep=0pt,
  rectangle,
  rounded corners=\wdim/10,
  text centered,
  thick,
  top color=white,
  bottom color=black!20,
]
\tikzstyle{arrow}=[
  ->,
  >=stealth,
  color=black!60,
  draw=black!60,
  shorten >=.5pt,
  thick,
]
\tikzstyle{arrowlabel}=[
  color=black!60,
  font={\tiny\sffamily\bfseries},
]
\tikzset{node distance=\wdim+\odim}
%%
\def\en#1{\foreignlanguage{english}{\emph{#1}}}
%%
\title{Programando aplicações multimídia no GStreamer}
\author{%
  Guilherme F\null.~Lima,
  Rodrigo C\null.\,M.~Santos,
  Roberto G\null.\,~de~A.~Azevedo
}
\begin{document}
\maketitle
\vskip-1.525\baselineskip\strut
\begin{abstract}
  \begin{otherlanguage}{english}
    This short course is an introduction to GStreamer, one of the main
    free/open-source frameworks for multimedia processing.  We start
    presenting GStreamer, its architecture and the dataflow programming
    model, and then adopt a hands-on approach.  Starting with an example, a
    simple video player, we introduce each concept of GStreamer’s basic C
    API and implement it over the initial example incrementally, so that at
    the end of the course we get a complete video player with support for
    the usual playback operations (start, stop, pause, seek, fast-forward,
    and rewind).  We also discuss sample filters---processing elements that
    manipulate audio and video samples.  We present the various filters
    natively available in GStreamer and show how one can extend the
    framework by creating a plugin with a custom filter that manipulates
    video samples.  The only prerequisite for the short course is a basic
    knowledge of the C programming language.  At the end of the short
    course, we expect that participants acquire a general view of GStreamer,
    and be able to create simple multimedia applications and explore its
    more advanced features.
  \end{otherlanguage}
\end{abstract}
\begin{resumo}
  Este minicurso é uma introdução ao GStreamer, um dos principais
  \en{frameworks} de código livre/aberto para processamento de dados
  multimídia.  Começamos apresentando o GStreamer, sua arquitetura e modelo
  de programação baseado em \en{dataflow}, e em seguida, adotamos uma
  abordagem prática.  Partindo de um exemplo inicial, um \en{player} de
  vídeo, introduzimos cada conceito da API~C básica do GStreamer e o
  implementamos sobre o exemplo, incrementando-o, de forma que ao final do
  minicurso obtemos um \en{player} de vídeo interativo completo, com suporte
  às operações usuais de reprodução de vídeo (\en{start}, \en{stop},
  \en{seek}, \en{fast-forward} e~\en{rewind}).  Discutimos também filtros de
  amostras---elementos que manipulam as amostras de áudio e vídeo.
  Apresentamos os diversos filtros disponíveis nativamente no GStreamer e
  mostramos como estender o \en{framework} criando um \en{plugin} com um
  filtro simples que manipula amostras de vídeo.  O único pré-requisito para
  o minicurso é um conhecimento básico da linguagem de programação~C\null.
  Ao final do minicurso, esperamos que os participantes tenham uma visão
  geral do GStreamer, e estejam aptos a criar aplicações simples e explorar
  os recursos mais avançados do \en{framework}.
\end{resumo}


\section{Introdução}
\label{sec:intro}

O GStreamer~\cite{gstreamer} é um dos principais \en{frameworks} de código
livre/aberto para processamento de dados multimídia.  Além de robusto e
flexível, ele suporta diversos formatos de áudio e vídeo, e é amplamente
utilizado na indústria e na academia~\cite{gstreamer-apps}.
O \en{framework} em si consiste de um conjunto de bibliotecas~C e
ferramentas relacionadas.  Neste minicurso, apresentamos tanto a parte
conceitual quanto a prática do \en{framework}.

Na parte conceitual, discutimos o modelo de computação \en{dataflow} no qual
o GStreamer se baseia, e que também é adotado por outros \en{frameworks} e
linguagens multimídia, por exemplo, DirectShow~\cite{Chatterjee-A-1997},
Pure Data~\cite{Puckette-M-S-2007}, CLAM~\cite{Amatriain-X-2008},
ChucK~\cite{Wang-G-2003}, Faust~\cite{Orlarey-Y-2009}, etc.  Nesse modelo,
uma aplicação multimídia estrutura-se como um grafo (\en{pipeline}) em que
os nós são elementos processadores e as arestas representam conexões entre
elementos por onde fluem as amostras de áudio e vídeo e dados de controle.
O modelo de \en{dataflow} é particularmente interessante para multimídia
porque possibilita implementações naturalmente paralelas, modulares e
escaláveis.

Na parte prática, apresentamos os principais conceitos da API~C básica do
GStreamer~1.10, sua versão estável mais atual, e ilustramos o uso dessa API
a partir da construção de um reprodutor (\en{player}) de vídeo.  Apesar de
aqui estarmos interessados apenas na reprodução (decodificação e
apresentação) de fluxos de mídia, essa mesma API pode ser utilizada para
capturar fluxos de áudio e vídeo, codificá-los e transmiti-los na rede.
O GStreamer suporta nativamente uma grande variedade de componentes para
tratar cada uma dessas fases de processamento e, portanto, pode ser usado
para construir diversos tipos de aplicações multimídia tais como editores de
vídeo, transcodificadores, transmissores de fluxos de mídia, \en{players} de
mídia, e motores de renderização de linguagens multimídia.

O restante do capítulo está organizado da seguinte forma.  Na
Seção~\ref{sec:ola} apresentamos uma versão preliminar do exemplo base do
minicurso: um \en{player} de vídeo simples porém funcional.  Na
Seção~\ref{sec:dissec} discutimos o que está por trás do código
aparentemente simples do exemplo anterior e reconstruímos o mesmo exemplo
usando a API básica (baixo nível) do GStreamer---a versão reconstruída é o
ponto de partida dos incrementos posteriores.  Na Seção~\ref{sec:filtros}
apresentamos os principais filtros de áudio e vídeo disponíveis no GStreamer
e discutimos como integrá-los ao exemplo.  Na Seção~\ref{sec:e/s}
adicionamos suporte à eventos de teclado e mouse ao \en{player} de vídeo, e
mostramos como injetar ou extrair amostras de uma aplicação GStreamer.  Na
Seção~\ref{sec:ops} discutimos a teoria por trás das operações usuais de
controle de reprodução (\en{pause}, \en{seek}, \en{fast-foward}
e~\en{rewind}) e implementamos suporte a cada uma delas no exemplo.  Na
Seção~\ref{sec:plugins} apresentamos a arquitetura de \en{plugins} do
GStreamer e mostramos como implementar e integrar ao exemplo um
\emph{plugin} simples contendo um elemento que manipula amostras de vídeo.
Finalmente, na Seção~\ref{sec:conclusao} discutimos brevemente algumas
funcionalidades avançadas do \en{framework} e apresentamos nossas
considerações finais.

Antes de ``mergulhar'' no código porém, é preciso entender o modelo
conceitual de computação no qual o GStreamer se baseia.  No restante dessa
seção apresentamos esse modelo, \emph{dataflow}, e discutimos a sua
instanciação particular no GStreamer.


\subsection*{O modelo \en{dataflow} e sua instanciação no GStreamer}
%% Dataflow

No modelo de computação \en{dataflow} os dados são processados enquanto
``fluem'' através de uma rede.  Essa rede estrutura-se como um grafo
dirigido em que os nós representam elementos de processamento, ou atores, e
as arestas representam conexões por onde fluem os dados.  Os atores recebem
dados através de suas portas de entrada e emitem dados através de suas porta
de saída.  Além disso, conceitualmente, atores são ativados por entrada,
isto é, executam sempre que os dados necessários estão disponíveis em suas
portas de entrada.  Um \en{pipeline} é um \en{dataflow} em que os dados
fluem através das arestas na mesma ordem em que foram
produzidos~\cite{Kahn-G-1977,Lee-E-A-1995}.  O modelo de computação
\en{dataflow}, e em especial, o modelo de \en{pipeline} é interessante para
multimídia porque aproxima a estrutura real do sistema da sua descrição
abstrata, idealizada na forma de diagrama de fluxo~\cite{Yviquel-H-2014}.
Além disso, o modelo de \en{dataflow} induz implementações flexíveis e
eficientes já que ele é naturalmente paralelo, modular e escalável:
(i)~paralelo porque conceitualmente os atores executam independentemente uns
dos outros; (ii)~modular porque a lógica de processamento está encapsulada
nos atores e pode ser reusada em diversos pontos do \en{dataflow};
e~(iii)~escalável porque a estrutura é naturalmente composicional---um
\en{dataflow} pode ser visto como um ator e vice versa.

A Figura~\ref{fig:pipeline-tipico} apresenta o leiaute de um \en{pipeline}
típico para processamento multimídia.  O leiaute nesse caso é de um pipeline
de uma aplicação GStreamer que decodifica e reproduz um vídeo em tempo real.
Os nós representam atores e as arestas representam as conexões por onde
fluem as amostras de áudio e vídeo e informações de controle.  Na
terminologia do GStreamer os atores do são chamados de ``elementos'' e as
portas de~``\en{pads}''.  Há dois tipos de \en{pads}, \en{sink pads} e
\en{source pads}.  As \en{sink pads} são as portas de entrada através das
quais o elemento consome dados, e as \en{source pads} são as portas de saída
através das quais o elemento produz dados.  Os elementos são classificados
de acordo com o tipo de suas \en{pads}.  Elementos produtores (\en{sources})
possuem apenas \en{source pads}, elementos processadores possuem ambos os
tipos, \en{source pads} e \en{sink pads}, e elementos consumidores
(\en{sinks}) possuem apenas \en{sink pads}.  Consequentemente, produtores
apenas produzem dados, processadores consomem e produzem dados resultantes,
e consumidores apenas consomem dados.

\begin{figure}[H]
  \centering
  \begin{tikzpicture}
    \node (filesrc) [element] {filesrc};
    \node [coordinate, above=.5\hdim of filesrc] (A) {};
    \node [coordinate, below=.5\hdim of filesrc] (B) {};
    %%
    \node (oggdemux) [element, right of=filesrc] {oggdemux};
    \node [coordinate, right of=oggdemux] (C) {};
    %%
    \node (vorbisdec) [element] at (C|-A) {vorbisdec};    
    \node (alsasink) [element, right of=vorbisdec] {alsasink};
    \node (theoradec) [element] at (C|-B) {theoradec};
    \node (ximagesink) [element, right of=theoradec] {ximagesink};
    %%
    \draw [arrow] (filesrc) -- (oggdemux);
    \node [coordinate] (X) at ($(oggdemux.east)+(0,.25\hdim)$) {};
    \node [coordinate] (Y) at ($(oggdemux.east)+(0,-.25\hdim)$) {};
    \draw [arrow] (X) -- node [arrowlabel, above] {A} ++(\odim/3,0)
                      -- ($(vorbisdec.west)-(\odim/3,0)$)
                      -- (vorbisdec.west);
    \draw [arrow] (Y) -- node [arrowlabel, below] {V} ++(\odim/3,0)
                      -- ($(theoradec.west)-(\odim/3,0)$)
                      -- (theoradec.west);
    \draw [arrow] (vorbisdec) -- (alsasink);
    \draw [arrow] (theoradec) -- (ximagesink);
  \end{tikzpicture}
  \caption{Um \en{pipeline} GStreamer que reproduz um arquivo de vídeo Ogg.}
  \label{fig:pipeline-tipico}
\end{figure}

Na figura acima, há um elemento produtor (``filesrc''), três processadores
(``oggdemux'', ``vorbisdec'' e ``theoradec'') e dois consumidores
(``alsasink'' e ``ximagesink'').  O elemento ``filesrc'' possui uma única
\en{source pad} que está conectada à \en{sink pad} do elemento subsequente,
``oggdemux'', ou seja, os dados produzidos pelo elemento ``filesrc'' fluem
através da sua \en{source pad} para a \en{sink pad} do elemento
``oggdemux''.  No diagrama a conexão entre as \en{pads} é representada pela
aresta direcionada entre os elementos ``filesrc'' e ``oggdemux''.
Similarmente, as demais arestas do diagrama denotam conexões entre
\en{source pads} e \en{sink pads}.

% Construir uma aplicação GStreamer é ``montar''

O \en{pipeline} da Figura~\ref{fig:pipeline-tipico} opera da seguinte forma.
O elemento ``filesrc'' lê um arquivo Ogg armazenado no sistema de arquivos e
escreve o fluxo de bytes resultantes na sua \en{source pad}.  Ogg é um
formato para multiplexação de fluxos de áudio, vídeo e texto.


\section{Olá mundo: Tocando um vídeo}
\label{sec:ola}

% Nesta seção...  Poderíamos usar implementar pipeline da figura para fazer
% nosso "olá mundo"---e é exatamente isso que vamos fazer na seção 3---mas
% há um jeito mais fácil.  Elementos encapsulam
% funcionalidade... gst-inspect


\section{Dissecando o exemplo anterior}
\label{sec:dissec}


\section{Filtros}
\label{sec:filtros}


\section{Entrada e saída}
\label{sec:e/s}


\section{\en{Pause}, \en{seek}, \en{fast-forward}
  e~\en{rewind}}
\label{sec:ops}


\section{Plugins}
\label{sec:plugins}


\section{Conclusão}
\label{sec:conclusao}


\bibliographystyle{plain}
\bibliography{bib}
\end{document}
% LocalWords:  GStreamer LocalWords mutiplexadores demultiplexadores sinks
%  LocalWords:  dataflow sources framework frameworks DirectShow Pure seek
%  LocalWords:  player players fast-foward rewind plugins
